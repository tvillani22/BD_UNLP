{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;font-size:40px\"><center>ACTIVIDAD 1</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modele una solución MapReduce, sugiriendo la utilización de funciones combiners en los casos que considere necesario, que permita obtener lo que se pide en cada inciso.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se detalla la solución implementada en cada inciso, explicando en cada caso la tarea de cada job, seguido del código. Obsérvese que en varios jobs, con el objetivo de utilizar combiners...\n",
    "- El formato de la salida de las funciones `map` fue adecuado para que admita los campos necesarios en una función `combiner` (cuyo output debe ser necesariamente igual a el de la función `map`).\n",
    "- El formato de la salida de las funciones `reduce` fue adecuado a ese mismo formato, para que se pueda usar la misma función `reduce` como función `combiner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLO SI CORRIENDO EN COLAB\n",
    "import sys, os\n",
    "!git clone https://github.com/tvillani22/BD_UNLP.git \n",
    "sys.path.append('/content/BD_UNLP/') # si se corre en Colab\n",
    "os.chdir('BD_UNLP/Notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR EL ARCHIVO `MRE.py` (en la carpeta raíz del repo si local o en `BD_UNLP/` si corriendo en Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from MRE import Job\n",
    "\n",
    "# Parámetros generales\n",
    "data_path = '../Data/website/'\n",
    "inputDir = data_path + 'input/'\n",
    "tempDir1 = data_path + \"temp/temp1\"\n",
    "tempDir2 = data_path + \"temp/temp2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inciso 1\n",
    ">**Obtener el usuario que más páginas distintas visitó.**\n",
    "\n",
    "***En la solución implementada, el primer job consolida las visitas de cada usuario a cada página usando esa tupla como `k2`, y calcula el número de visitas y el tiempo total, para ese par. Esto último no es necesario y solo se hace aquí para generalizar este primer job y poder usarlo como primer job en los otros incisos.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = data_path + 'output/output1/'\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    id_user = key\n",
    "    id_page = value.split()[0]\n",
    "    time = value.split()[1]\n",
    "    context.write((id_user, id_page), (1, time)) \n",
    "\n",
    "def fred(key, values, context):\n",
    "    id_user = key[0]\n",
    "    id_page = key[1]\n",
    "    t_total = 0\n",
    "    n_total = 0\n",
    "    for v in values:\n",
    "        n_acum_loc = v[0]\n",
    "        t_acum_loc = v[1]\n",
    "        n_total += int(n_acum_loc)\n",
    "        t_total += int(t_acum_loc)\n",
    "    context.write((id_user, id_page), (n_total, t_total))\n",
    "\n",
    "job = Job(inputDir, tempDir1, fmap, fred)\n",
    "job.setCombiner(fred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El segundo job acumula, para cada usuario, el número de páginas que visitó (sin importar cuántas veces cada una).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmap2(key, value, context):\n",
    "    id_user = key\n",
    "    context.write(id_user, 1)\n",
    "\n",
    "def fred2(key, values, context):\n",
    "    id_user = key\n",
    "    num_sitios = 0\n",
    "    for v in values:\n",
    "        num_sitios += v\n",
    "    context.write(id_user, num_sitios)\n",
    "\n",
    "job2 = Job(tempDir1, tempDir2, fmap2, fred2)\n",
    "job2.setCombiner(fred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El tercer job busca el usuario que más páginas distintas visitó.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmap3(key, value, context):\n",
    "    id_user = key\n",
    "    num_sitios = value\n",
    "    context.write(99, (id_user, num_sitios))\n",
    "\n",
    "def fred3(key, values, context):\n",
    "    num_sitios_max = 0\n",
    "    id_user_nmax = None\n",
    "    for v in values:\n",
    "        id_user = v[0]\n",
    "        num_sitios = int(v[1])\n",
    "        if num_sitios >  num_sitios_max:\n",
    "            num_sitios_max = num_sitios\n",
    "            id_user_nmax = id_user\n",
    "    context.write(99, (id_user_nmax, num_sitios_max))\n",
    "    \n",
    "job3 = Job(tempDir2, outputDir, fmap3, fred3)\n",
    "job3.setCombiner(fred3)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejecutando...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1 completado con éxito.\n",
      "Job 2 completado con éxito.\n",
      "Job 3 completado con éxito.\n",
      "\n",
      "RESULTADO \n",
      "El usuario que más páginas distintas visitó fue el usuario número 9458, con 6.\n"
     ]
    }
   ],
   "source": [
    "success = job.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 1 completado con éxito.')\n",
    "    success = job2.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 2 completado con éxito.')\n",
    "    success = job3.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 3 completado con éxito.')\n",
    "    with open(outputDir + 'output.txt', 'rt') as fh:    \n",
    "        linea = next(fh)\n",
    "        id_user_nmax = linea.rstrip().split()[1]\n",
    "        num_sitios_max = linea.rstrip().split()[2]\n",
    "    print(f'\\nRESULTADO \\nEl usuario que más páginas distintas visitó '\n",
    "          f'fue el usuario número {id_user_nmax}, con {num_sitios_max}.')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Y el DAG para este proceso es...***\n",
    "![image.png](../imgs/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inciso 2\n",
    ">**Obtener la página más visitada (en cuanto a tiempo de visita) por cada usuario siempre que la página haya sido visitada más de V veces por ese usuario (V es parámetro de la consulta).**\n",
    "\n",
    "***En la solución implementada el primer Job, igual al del inciso anterior, consolida las visitas de cada usuario a cada página usando esa tupla como `k2`, y calcula el número de visitas y el tiempo total, para ese par.*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = data_path + \"output/output2/\"\n",
    "V = 1  # parámetro de visitas minimas\n",
    "parametros = {'visitas_minimas': V}\n",
    "\n",
    "job = Job(inputDir, tempDir1, fmap, fred)\n",
    "job.setCombiner(fred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El segundo Job busca, para cada usuario, la página que tiene el tiempo máximo de visita por ese usuario, guardando también el número de visitas que se hicieron. Finalmente, solo incluye el par usuario-página en el output si ese número de visitas es superior al parámetro V. En este caso, las funciones `combiner` y `reduce` pueden hacerse muy similares, pero no iguales. Por ello, para ahorrar código, se las implementa a través de una tercera función llamada `buscar_tmax()`.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmap2(key, value, context):\n",
    "    id_user = key\n",
    "    id_page = value.split()[0]\n",
    "    n_total = value.split()[1]\n",
    "    t_total = value.split()[2]            \n",
    "    context.write(id_user, (id_page, n_total, t_total))\n",
    "\n",
    "def buscar_maxt(key, values, context):\n",
    "    id_user = key\n",
    "    t_max = 0\n",
    "    n_tmax = None\n",
    "    id_page_tmax = None\n",
    "    for v in values:\n",
    "        id_page = int(v[0])\n",
    "        n_total = int(v[1])          \n",
    "        t_total = int(v[2])\n",
    "        if t_total > t_max:\n",
    "            t_max = t_total\n",
    "            id_page_tmax = id_page\n",
    "            n_tmax = n_total\n",
    "    return id_user, (id_page_tmax, n_tmax, t_max)\n",
    "\n",
    "def fcomb(key, values, context):\n",
    "    context.write(buscar_maxt(key, values, context))   \n",
    "    \n",
    "def fred2(key, values, context):\n",
    "    id_user, tup = buscar_maxt(key, values, context)\n",
    "    id_page_tmax, n_tmax, t_max = tup\n",
    "    if int(n_tmax) > context['visitas_minimas']:\n",
    "        context.write(id_user, (id_page_tmax, n_tmax, t_max)) \n",
    "\n",
    "job2 = Job(tempDir1, outputDir, fmap2, fred2)\n",
    "job2.setParams(parametros)\n",
    "job2.setCombiner(fcomb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejecutando...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1 completado con éxito.\n",
      "Job 2 completado con éxito.\n",
      "\n",
      "RESULTADO \n",
      "Usuario: 14448; Página: 1026; Número de visitas: 2; Tiempo total: 114\n"
     ]
    }
   ],
   "source": [
    "success = job.waitForCompletion()\n",
    "if success:\n",
    "    print('Job 1 completado con éxito.')\n",
    "    success = job2.waitForCompletion()\n",
    "if success:\n",
    "    print('Job 2 completado con éxito.')\n",
    "    n_lineas = sum(1 for line in open(outputDir + 'output.txt', 'rt'))\n",
    "    if n_lineas == 0:\n",
    "        print(f'No hay página que haya sido visitada más de {V} veces '\n",
    "                'por un mismo usuario.')\n",
    "    elif n_lineas < 10:\n",
    "        with open(outputDir + 'output.txt', 'rt') as fh:    \n",
    "            for linea in fh:\n",
    "                id_user, id_page, n_visitas, time = linea.split()\n",
    "                print(f'\\nRESULTADO \\nUsuario: {id_user}; Página: {id_page}; '\n",
    "                      f'Número de visitas: {n_visitas}; Tiempo total: {time}')\n",
    "    else:\n",
    "        print('Resultado extenso, acceder en el output file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Y el DAG para este proceso es...***\n",
    "\n",
    "![image.png](../imgs/12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inciso 3\n",
    ">**Obtener la página más visitada (en cuanto a cantidad de visitas, sin importar el tiempo de permanencia) por al menos U usuarios distintos (U es parámetro de la consulta).**\n",
    "\n",
    "***En la solución implementada el primer job, igual al de los dos incisos previos, consolida las visitas de cada usuario a cada página usando esa tupla como `k2`, y calcula el número de visitas y el tiempo total para ese par.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = data_path + \"output/output3/\"\n",
    "U = 6  # parámetro de usuarios minimos\n",
    "parametros = {'usuarios_minimos': U}\n",
    "\n",
    "job = Job(inputDir, tempDir1, fmap, fred)\n",
    "job.setCombiner(fred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El segundo job cuenta, para cada página, el número total de usuarios y de visitas (contando todas las visitas de cada usuario) que recibió.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmap2(key, value, context):\n",
    "    id_user = key\n",
    "    id_page = value.split()[0]\n",
    "    n_visitas = int(value.split()[1])\n",
    "    n_usuarios = 1 \n",
    "    context.write(id_page, (n_visitas, n_usuarios))\n",
    "    \n",
    "def fred2(key, values, context):\n",
    "    id_page = key\n",
    "    n_visitas_tot = 0\n",
    "    n_usuarios_tot = 0\n",
    "    for v in values:\n",
    "        n_visitas = v[0] \n",
    "        n_usuarios = v[1]\n",
    "        n_visitas_tot += n_visitas\n",
    "        n_usuarios_tot += n_usuarios\n",
    "    if n_usuarios_tot >= context['usuarios_minimos']:\n",
    "        context.write(id_page, (n_visitas_tot, n_usuarios_tot))\n",
    "\n",
    "job2 = Job(tempDir1, tempDir2, fmap2, fred2)\n",
    "job2.setCombiner(fred2)\n",
    "job2.setParams(parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El tercer job se queda con la página más visitada, entre aquellas que fueron visitadas por al menos U usuarios.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmap3(key, value, context):\n",
    "    id_page = key\n",
    "    n_visitas_tot = int(value.split()[0])\n",
    "    n_usuarios_tot = int(value.split()[1])\n",
    "    context.write(99, (id_page, n_visitas_tot, n_usuarios_tot))\n",
    "\n",
    "def fred3(key, values, context):\n",
    "    n_visitas_max = 0\n",
    "    id_page_vmax = None\n",
    "    n_usuarios_vmax = 0\n",
    "    maximos = []\n",
    "    # output nulo si en combiner ningun input cumple condicion\n",
    "    for v in values:\n",
    "        id_page = v[0]\n",
    "        n_visitas = v[1]\n",
    "        n_usuarios = v[2]\n",
    "        if n_visitas > n_visitas_max:\n",
    "            n_visitas_max = n_visitas\n",
    "            maximos = [[id_page, n_visitas, n_usuarios]]\n",
    "        elif n_visitas == n_visitas_max:\n",
    "            maximos.append([id_page, n_visitas, n_usuarios])\n",
    "    for maximo in maximos:\n",
    "        context.write(99, tuple(maximo))\n",
    "\n",
    "job3 = Job(tempDir2, outputDir, fmap3, fred3)\n",
    "job3.setCombiner(fred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejecutando...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1 completado con éxito.\n",
      "Job 2 completado con éxito.\n",
      "Job 3 completado con éxito.\n",
      "\n",
      "RESULTADO \n",
      "Las páginas más visitadas, entre aquellas que fueron visitadas por al menos 6 usuarios, son:\n",
      "\n",
      "id_pag: 2390; número de visitas: 8; número de visitas: 8; número de usuarios: 8.\n",
      "id_pag: 1694; número de visitas: 8; número de visitas: 8; número de usuarios: 8.\n",
      "id_pag: 1712; número de visitas: 8; número de visitas: 8; número de usuarios: 8.\n",
      "id_pag: 3794; número de visitas: 8; número de visitas: 8; número de usuarios: 8.\n"
     ]
    }
   ],
   "source": [
    "success = job.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 1 completado con éxito.')\n",
    "    success = job2.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 2 completado con éxito.')\n",
    "    success = job3.waitForCompletion()\n",
    "\n",
    "if success:\n",
    "    print('Job 3 completado con éxito.')\n",
    "    with open(outputDir + 'output.txt', 'rt') as fh:\n",
    "        if fh is not None:\n",
    "            num_lineas = len(fh.readlines())\n",
    "            fh.seek(0)\n",
    "            if num_lineas == 1:\n",
    "                linea = next(fh)\n",
    "                print(f'\\nRESULTADO \\nLa página más visitada, entre aquellas que fueron '\n",
    "                      f'visitadas por al menos {U} usuarios, fue la {id_page}, que fue '\n",
    "                      f'visitada un total de {n_visitas} veces, por {n_usuarios} distintos.')\n",
    "            elif num_lineas < 5:\n",
    "                print(f'\\nRESULTADO \\nLas páginas más visitadas, entre aquellas que fueron '\n",
    "                      f'visitadas por al menos {U} usuarios, son:\\n')\n",
    "                for linea in fh:\n",
    "                    id_page, n_visitas, n_usuarios = linea.rstrip().split()[1:]\n",
    "                    print(f'id_pag: {id_page}; número de visitas: {n_visitas}; '\n",
    "                          f'número de visitas: {n_visitas}; número de usuarios: {n_usuarios}.') \n",
    "            else:\n",
    "                print('Resultado extenso, acceder en el output file.')\n",
    "        else:\n",
    "            print(f'No hay página que haya sido visitada por al menos {U} usuarios.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Y el DAG para este proceso es...***\n",
    "![image.png](../imgs/13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
